---
title: LangChain with Xata
navTitle: LangChain
keywords: ['AI', 'vector store', 'memory store']
description:
slug: integrations/langchain
published: true
---

[LangChain](https://www.langchain.com/) is an open-source framework designed to simplify the development of applications driven by language models, especially large language models (LLMs). Instead of relying on API interactions, LangChain encourages applications to connect with data sources and engage with the environment dynamically. This framework offers two primary advantages:

- presents readily deployable building blocks tailored for language model utilization;
- introduces the concept of "chains" that amalgamate these building blocks for specific tasks, granting an accessible entry point while retaining room for customization. This documentation is thoughtfully organized into these pivotal facets: the fundamental building blocks and the application-specific chains.

## Integration options

- Xata as a vector Store in LangChain (Python): Use Xata as a vector store within LangChain. This integration enables you to store documents with embeddings in a Xata table, facilitating vector searches. Leveraging the Python SDK this integration supports metadata-based filtering, in which metadata is represented through Xata columns.

- Xata as a vector vtore in LangChain.js (TypeScript/JavaScript): Similar to the Python integration, you can incorporate Xata as a vector store within LangChain.js.

- Xata as a emory store in LangChain: Make use of Xata as a memory store within LangChain for storing chat message history. This is particularly useful for AI chat sessions, functioning as a "memory" for applications powered by large language models(LLM). The messages are effectively stored to enhance contextual understanding.

- Xata as a memory store in LangChain.js (TypeScript/JavaScript): This option offers the same functionality as the Python integration, adapted for TypeScript/JavaScript environments.
